{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-04T03:55:47.485019Z",
     "start_time": "2019-07-04T03:55:45.668802Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys, time\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import NoSuchWindowException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from datetime import datetime\n",
    "from openpyxl import Workbook\n",
    "import os\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Assume we would like to scrap contents by google driver, <n> you need to download 'chromedriver' and put in the path you like.(http://chromedriver.chromium.org/downloads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-04T03:55:47.556808Z",
     "start_time": "2019-07-04T03:55:47.486967Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>TITLE_URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dell Prime Day slashes $200 off the XPS 15 957...</td>\n",
       "      <td>https://www.notebookcheck.net/Dell-Prime-Day-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Windows Calculator ports for Android, iOS and ...</td>\n",
       "      <td>https://www.notebookcheck.net/Windows-Calculat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sharkoon claims its Gaming DAC Pro S can deliv...</td>\n",
       "      <td>https://www.notebookcheck.net/Sharkoon-claims-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Motorola cancels plans to release Pie for its ...</td>\n",
       "      <td>https://www.notebookcheck.net/Motorola-cancels...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>There are two Snapdragon 855-powered Samsung G...</td>\n",
       "      <td>https://www.notebookcheck.net/There-are-two-Sn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               TITLE  \\\n",
       "0  Dell Prime Day slashes $200 off the XPS 15 957...   \n",
       "1  Windows Calculator ports for Android, iOS and ...   \n",
       "2  Sharkoon claims its Gaming DAC Pro S can deliv...   \n",
       "3  Motorola cancels plans to release Pie for its ...   \n",
       "4  There are two Snapdragon 855-powered Samsung G...   \n",
       "\n",
       "                                           TITLE_URL  \n",
       "0  https://www.notebookcheck.net/Dell-Prime-Day-s...  \n",
       "1  https://www.notebookcheck.net/Windows-Calculat...  \n",
       "2  https://www.notebookcheck.net/Sharkoon-claims-...  \n",
       "3  https://www.notebookcheck.net/Motorola-cancels...  \n",
       "4  https://www.notebookcheck.net/There-are-two-Sn...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('D:/notebookcheck_url.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-04T03:55:47.563765Z",
     "start_time": "2019-07-04T03:55:47.558776Z"
    }
   },
   "outputs": [],
   "source": [
    "url_list = df['TITLE_URL'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-04T03:56:21.113406Z",
     "start_time": "2019-07-04T03:56:21.108419Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(url_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-04T03:56:21.534796Z",
     "start_time": "2019-07-04T03:56:21.530810Z"
    }
   },
   "outputs": [],
   "source": [
    "j=0 # help to record which url we've get (chromedriver sometimes dead when there are many urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-04T03:56:21.935811Z",
     "start_time": "2019-07-04T03:56:21.931854Z"
    }
   },
   "outputs": [],
   "source": [
    "# set save path\n",
    "save_path = 'D:/'\n",
    "name_of_file = 'Notebookcheck_'+datetime.now().strftime('%Y-%m-%d')\n",
    "completeName = os.path.join(save_path, name_of_file+\"_\"+str(j)+\".xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrap through chrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-04T03:57:47.769Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "\n",
    "chrome_path = \"C:\\selenium_driver_chrome\\chromedriver_1.exe\"\n",
    "driver = webdriver.Chrome(chrome_path)\n",
    "\n",
    "ws.append([\"INDEX\", \"URL\", \"AUTHOR\", \"DATE\", \"TITLE\", \"ARTICLE\", \"SCRAP_DATE\"])\n",
    "\n",
    "while j <= (len(url_list)-1):\n",
    "#for j in range(0, len(url_list)):\n",
    "    url = url_list[j]\n",
    "    print(j)\n",
    "    should_reopen_1 = True\n",
    "    while should_reopen_1:\n",
    "        should_reopen_1 = False\n",
    "        try:\n",
    "            driver.implicitly_wait(3)\n",
    "            driver.get(url)\n",
    "        except:\n",
    "            error_type, error_obj, error_info = sys.exc_info()\n",
    "            should_reopen_1 = True\n",
    "\n",
    "    time.sleep(3)\n",
    "\n",
    "###################################################################3\n",
    "# start \n",
    "    #locator = (By.CSS_SELECTOR, 'div.Discussion')\n",
    "    try:\n",
    "        #WebDriverWait(driver, 600, 5).until(EC.presence_of_element_located(locator))\n",
    "        tables = driver.find_elements_by_id('content')\n",
    "    except Exception as ex:\n",
    "        print(str(ex))\n",
    "        continue # pass all code below and continue with i+1\n",
    "\n",
    "    if tables==[]:\n",
    "        print(\"url_index = %d \" %j)\n",
    "        not_find_table.append(j)\n",
    "    else:\n",
    "        for rev in tables:\n",
    "            \n",
    "            #print(rev.find_element_by_css_selector('h1').text)\n",
    "            abstract = (rev.find_element_by_class_name('news-abstract').text)\n",
    "            author = (rev.find_element_by_class_name('news-author-date').text).split(',')[0].strip()\n",
    "            date = (rev.find_element_by_class_name('news-author-date').text).split(',')[1].strip()\n",
    "            tags = (rev.find_element_by_class_name('news-tags').text)\n",
    "            \n",
    "            content = []\n",
    "            for t in (rev.find_elements_by_class_name('bodytext')):\n",
    "                content.append(t.text.strip())\n",
    "            contents = \" \".join(content)\n",
    "\n",
    "\n",
    "    ws.append([j, url, url_list[j], author, date, tags, contents, datetime.now().strftime('%Y-%m-%d')])\n",
    "\n",
    "    filename = completeName\n",
    "    wb.save(filename) # save to excel workbook every loop\n",
    "    j = j+1\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
